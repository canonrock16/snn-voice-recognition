{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a02530-d151-40ac-87d6-7a4a23c04a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from time import time as t\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from bindsnet.analysis.plotting import (\n",
    "    plot_assignments,\n",
    "    plot_input,\n",
    "    plot_performance,\n",
    "    plot_spikes,\n",
    "    plot_voltages,\n",
    "    plot_weights,\n",
    ")\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.encoding import PoissonEncoder\n",
    "from bindsnet.evaluation import all_activity, assign_labels, proportion_weighting\n",
    "from bindsnet.models import DiehlAndCook2015\n",
    "from bindsnet.network.monitors import Monitor\n",
    "from bindsnet.utils import get_square_assignments, get_square_weights\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d939362f-3333-4999-8b2f-a0a439fefe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--seed\", type=int, default=0)\n",
    "# parser.add_argument(\"--n_neurons\", type=int, default=100)\n",
    "# parser.add_argument(\"--n_epochs\", type=int, default=1)\n",
    "# parser.add_argument(\"--n_test\", type=int, default=10000)\n",
    "# parser.add_argument(\"--n_train\", type=int, default=60000)\n",
    "# parser.add_argument(\"--n_workers\", type=int, default=-1)\n",
    "# parser.add_argument(\"--exc\", type=float, default=22.5)\n",
    "# parser.add_argument(\"--inh\", type=float, default=120)\n",
    "# parser.add_argument(\"--theta_plus\", type=float, default=0.05)\n",
    "# parser.add_argument(\"--time\", type=int, default=250)\n",
    "# parser.add_argument(\"--dt\", type=int, default=1.0)\n",
    "# parser.add_argument(\"--intensity\", type=float, default=128)\n",
    "# parser.add_argument(\"--progress_interval\", type=int, default=10)\n",
    "# parser.add_argument(\"--update_interval\", type=int, default=250)\n",
    "# parser.add_argument(\"--train\", dest=\"train\", action=\"store_true\")\n",
    "# parser.add_argument(\"--test\", dest=\"train\", action=\"store_false\")\n",
    "# parser.add_argument(\"--plot\", dest=\"plot\", action=\"store_true\")\n",
    "# parser.add_argument(\"--gpu\", dest=\"gpu\", action=\"store_true\")\n",
    "# parser.set_defaults(plot=True, gpu=True)\n",
    "\n",
    "seed = 0\n",
    "n_neurons = 100\n",
    "n_epochs = 1\n",
    "n_test = 10000\n",
    "n_train = 60000\n",
    "n_workers = -1\n",
    "exc = 22.5\n",
    "inh = 120\n",
    "theta_plus = 0.05\n",
    "time = 250\n",
    "dt = 1.0\n",
    "intensity = 128\n",
    "progress_interval = 10\n",
    "update_interval = 250\n",
    "train = True\n",
    "plot = False\n",
    "gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83e60c62-7520-4abd-976b-1004d43a8410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Device =  cpu\n"
     ]
    }
   ],
   "source": [
    "# Sets up Gpu use\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if gpu and torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "else:\n",
    "    torch.manual_seed(seed)\n",
    "    device = \"cpu\"\n",
    "    if gpu:\n",
    "        gpu = False\n",
    "\n",
    "torch.set_num_threads(os.cpu_count() - 1)\n",
    "print(\"Running on Device = \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f98b8629-f8df-44d7-b4bd-878f62f550df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determines number of workers to use\n",
    "if n_workers == -1:\n",
    "    n_workers = 0  # gpu * 4 * torch.cuda.device_count()\n",
    "\n",
    "if not train:\n",
    "    update_interval = n_test\n",
    "\n",
    "n_sqrt = int(np.ceil(np.sqrt(n_neurons)))\n",
    "start_intensity = intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "29db2bcd-6095-4ffc-bd0e-af9aeebc3402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build network.\n",
    "network = DiehlAndCook2015(\n",
    "    n_inpt=784,\n",
    "    n_neurons=n_neurons,\n",
    "    exc=exc,\n",
    "    inh=inh,\n",
    "    dt=dt,\n",
    "    norm=78.4,\n",
    "    theta_plus=theta_plus,\n",
    "    inpt_shape=(1, 28, 28),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "541a04c5-740b-44ac-8f92-8289b596c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directs network to GPU\n",
    "if gpu:\n",
    "    network.to(\"cuda\")\n",
    "\n",
    "# Load MNIST data.\n",
    "train_dataset = MNIST(\n",
    "    PoissonEncoder(time=time, dt=dt),\n",
    "    None,\n",
    "    root=os.path.join(\"..\", \"..\", \"data\", \"MNIST\"),\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf7bb771-b25c-47f2-a48a-f4700584a6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record spikes during the simulation.\n",
    "spike_record = torch.zeros((update_interval, int(time / dt), n_neurons), device=device)\n",
    "\n",
    "# Neuron assignments and spike proportions.\n",
    "n_classes = 10\n",
    "assignments = -torch.ones(n_neurons, device=device)\n",
    "proportions = torch.zeros((n_neurons, n_classes), device=device)\n",
    "rates = torch.zeros((n_neurons, n_classes), device=device)\n",
    "\n",
    "# Sequence of accuracy estimates.\n",
    "accuracy = {\"all\": [], \"proportion\": []}\n",
    "\n",
    "# Voltage recording for excitatory and inhibitory layers.\n",
    "exc_voltage_monitor = Monitor(network.layers[\"Ae\"], [\"v\"], time=int(time / dt), device=device)\n",
    "inh_voltage_monitor = Monitor(network.layers[\"Ai\"], [\"v\"], time=int(time / dt), device=device)\n",
    "network.add_monitor(exc_voltage_monitor, name=\"exc_voltage\")\n",
    "network.add_monitor(inh_voltage_monitor, name=\"inh_voltage\")\n",
    "\n",
    "# Set up monitors for spikes and voltages\n",
    "spikes = {}\n",
    "for layer in set(network.layers):\n",
    "    spikes[layer] = Monitor(network.layers[layer], state_vars=[\"s\"], time=int(time / dt), device=device)\n",
    "    network.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)\n",
    "\n",
    "voltages = {}\n",
    "for layer in set(network.layers) - {\"X\"}:\n",
    "    voltages[layer] = Monitor(network.layers[layer], state_vars=[\"v\"], time=int(time / dt), device=device)\n",
    "    network.add_monitor(voltages[layer], name=\"%s_voltages\" % layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "53158751-e815-445c-998f-eb983577698f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Begin training.\n",
      "\n",
      "Progress: 0 / 1 (0.0007 seconds)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                               | 250/60000 [00:58<3:53:37,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 11.20 (last), 11.20 (average), 11.20 (best)\n",
      "Proportion weighting accuracy: 11.20 (last), 11.20 (average), 11.20 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                               | 500/60000 [01:58<3:48:03,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 32.00 (last), 21.60 (average), 32.00 (best)\n",
      "Proportion weighting accuracy: 32.80 (last), 22.00 (average), 32.80 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                               | 750/60000 [02:56<3:45:29,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 32.40 (last), 25.20 (average), 32.40 (best)\n",
      "Proportion weighting accuracy: 36.40 (last), 26.80 (average), 36.40 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                              | 1000/60000 [03:53<3:43:21,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 28.00 (last), 25.90 (average), 32.40 (best)\n",
      "Proportion weighting accuracy: 28.00 (last), 27.10 (average), 36.40 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                              | 1250/60000 [04:50<3:41:22,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 35.60 (last), 27.84 (average), 35.60 (best)\n",
      "Proportion weighting accuracy: 35.60 (last), 28.80 (average), 36.40 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▏                                             | 1500/60000 [05:47<3:40:20,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 30.80 (last), 28.33 (average), 35.60 (best)\n",
      "Proportion weighting accuracy: 30.80 (last), 29.13 (average), 36.40 (best)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                             | 1572/60000 [06:04<3:46:04,  4.31it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ks/wq6gv63535qgjwwby2t506c00000gn/T/ipykernel_70371/3989386248.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# Run the network on the input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_time_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# Get voltage recording.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/snn-voice-recognition/.venv/lib/python3.9/site-packages/bindsnet/network/network.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, inputs, time, one_step, **kwargs)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurrent_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/snn-voice-recognition/.venv/lib/python3.9/site-packages/bindsnet/network/nodes.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;31m# Decrement refractory counters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefrac_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx\u001b[0m  \u001b[0;31m# interlaced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inpt_ims, inpt_axes = None, None\n",
    "spike_ims, spike_axes = None, None\n",
    "weights_im = None\n",
    "assigns_im = None\n",
    "perf_ax = None\n",
    "voltage_axes, voltage_ims = None, None\n",
    "\n",
    "# Train the network.\n",
    "print(\"\\nBegin training.\\n\")\n",
    "start = t()\n",
    "for epoch in range(n_epochs):\n",
    "    labels = []\n",
    "\n",
    "    if epoch % progress_interval == 0:\n",
    "        print(\"Progress: %d / %d (%.4f seconds)\" % (epoch, n_epochs, t() - start))\n",
    "        start = t()\n",
    "\n",
    "    # Create a dataloader to iterate and batch data\n",
    "    dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=n_workers, pin_memory=gpu)\n",
    "\n",
    "    for step, batch in enumerate(tqdm(dataloader)):\n",
    "        if step > n_train:\n",
    "            break\n",
    "        # Get next input sample.\n",
    "        inputs = {\"X\": batch[\"encoded_image\"].view(int(time / dt), 1, 1, 28, 28)}\n",
    "        if gpu:\n",
    "            inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "\n",
    "        if step % update_interval == 0 and step > 0:\n",
    "            # Convert the array of labels into a tensor\n",
    "            label_tensor = torch.tensor(labels, device=device)\n",
    "\n",
    "            # Get network predictions.\n",
    "            all_activity_pred = all_activity(spikes=spike_record, assignments=assignments, n_labels=n_classes)\n",
    "            proportion_pred = proportion_weighting(\n",
    "                spikes=spike_record,\n",
    "                assignments=assignments,\n",
    "                proportions=proportions,\n",
    "                n_labels=n_classes,\n",
    "            )\n",
    "\n",
    "            # Compute network accuracy according to available classification strategies.\n",
    "            accuracy[\"all\"].append(100 * torch.sum(label_tensor.long() == all_activity_pred).item() / len(label_tensor))\n",
    "            accuracy[\"proportion\"].append(100 * torch.sum(label_tensor.long() == proportion_pred).item() / len(label_tensor))\n",
    "\n",
    "            print(\n",
    "                \"\\nAll activity accuracy: %.2f (last), %.2f (average), %.2f (best)\"\n",
    "                % (\n",
    "                    accuracy[\"all\"][-1],\n",
    "                    np.mean(accuracy[\"all\"]),\n",
    "                    np.max(accuracy[\"all\"]),\n",
    "                )\n",
    "            )\n",
    "            print(\n",
    "                \"Proportion weighting accuracy: %.2f (last), %.2f (average), %.2f\"\n",
    "                \" (best)\\n\"\n",
    "                % (\n",
    "                    accuracy[\"proportion\"][-1],\n",
    "                    np.mean(accuracy[\"proportion\"]),\n",
    "                    np.max(accuracy[\"proportion\"]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Assign labels to excitatory layer neurons.\n",
    "            assignments, proportions, rates = assign_labels(\n",
    "                spikes=spike_record,\n",
    "                labels=label_tensor,\n",
    "                n_labels=n_classes,\n",
    "                rates=rates,\n",
    "            )\n",
    "\n",
    "            labels = []\n",
    "\n",
    "        labels.append(batch[\"label\"])\n",
    "\n",
    "        # Run the network on the input.\n",
    "        network.run(inputs=inputs, time=time, input_time_dim=1)\n",
    "\n",
    "        # Get voltage recording.\n",
    "        exc_voltages = exc_voltage_monitor.get(\"v\")\n",
    "        inh_voltages = inh_voltage_monitor.get(\"v\")\n",
    "\n",
    "        # Add to spikes recording.\n",
    "        spike_record[step % update_interval] = spikes[\"Ae\"].get(\"s\").squeeze()\n",
    "\n",
    "        # Optionally plot various simulation information.\n",
    "        if plot:\n",
    "            image = batch[\"image\"].view(28, 28)\n",
    "            inpt = inputs[\"X\"].view(time, 784).sum(0).view(28, 28)\n",
    "            input_exc_weights = network.connections[(\"X\", \"Ae\")].w\n",
    "            square_weights = get_square_weights(input_exc_weights.view(784, n_neurons), n_sqrt, 28)\n",
    "            square_assignments = get_square_assignments(assignments, n_sqrt)\n",
    "            spikes_ = {layer: spikes[layer].get(\"s\") for layer in spikes}\n",
    "            voltages = {\"Ae\": exc_voltages, \"Ai\": inh_voltages}\n",
    "            inpt_axes, inpt_ims = plot_input(image, inpt, label=batch[\"label\"], axes=inpt_axes, ims=inpt_ims)\n",
    "            spike_ims, spike_axes = plot_spikes(spikes_, ims=spike_ims, axes=spike_axes)\n",
    "            weights_im = plot_weights(square_weights, im=weights_im)\n",
    "            assigns_im = plot_assignments(square_assignments, im=assigns_im)\n",
    "            perf_ax = plot_performance(accuracy, x_scale=update_interval, ax=perf_ax)\n",
    "            voltage_ims, voltage_axes = plot_voltages(voltages, ims=voltage_ims, axes=voltage_axes, plot_type=\"line\")\n",
    "\n",
    "            plt.pause(1e-8)\n",
    "\n",
    "        network.reset_state_variables()  # Reset state variables.\n",
    "\n",
    "print(\"Progress: %d / %d (%.4f seconds)\" % (epoch + 1, n_epochs, t() - start))\n",
    "print(\"Training complete.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9efb532-6649-4d30-86e7-33fe4183f1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data.\n",
    "test_dataset = MNIST(\n",
    "    PoissonEncoder(time=time, dt=dt),\n",
    "    None,\n",
    "    root=os.path.join(\"..\", \"..\", \"data\", \"MNIST\"),\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]),\n",
    ")\n",
    "\n",
    "# Sequence of accuracy estimates.\n",
    "accuracy = {\"all\": 0, \"proportion\": 0}\n",
    "\n",
    "# Record spikes during the simulation.\n",
    "spike_record = torch.zeros((1, int(time / dt), n_neurons), device=device)\n",
    "\n",
    "# Train the network.\n",
    "print(\"\\nBegin testing\\n\")\n",
    "network.train(mode=False)\n",
    "start = t()\n",
    "\n",
    "pbar = tqdm(total=n_test)\n",
    "for step, batch in enumerate(test_dataset):\n",
    "    if step >= n_test:\n",
    "        break\n",
    "    # Get next input sample.\n",
    "    inputs = {\"X\": batch[\"encoded_image\"].view(int(time / dt), 1, 1, 28, 28)}\n",
    "    if gpu:\n",
    "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "\n",
    "    # Run the network on the input.\n",
    "    network.run(inputs=inputs, time=time, input_time_dim=1)\n",
    "\n",
    "    # Add to spikes recording.\n",
    "    spike_record[0] = spikes[\"Ae\"].get(\"s\").squeeze()\n",
    "\n",
    "    # Convert the array of labels into a tensor\n",
    "    label_tensor = torch.tensor(batch[\"label\"], device=device)\n",
    "\n",
    "    # Get network predictions.\n",
    "    all_activity_pred = all_activity(spikes=spike_record, assignments=assignments, n_labels=n_classes)\n",
    "    proportion_pred = proportion_weighting(\n",
    "        spikes=spike_record,\n",
    "        assignments=assignments,\n",
    "        proportions=proportions,\n",
    "        n_labels=n_classes,\n",
    "    )\n",
    "\n",
    "    # Compute network accuracy according to available classification strategies.\n",
    "    accuracy[\"all\"] += float(torch.sum(label_tensor.long() == all_activity_pred).item())\n",
    "    accuracy[\"proportion\"] += float(torch.sum(label_tensor.long() == proportion_pred).item())\n",
    "\n",
    "    network.reset_state_variables()  # Reset state variables.\n",
    "    pbar.set_description_str(\"Test progress: \")\n",
    "    pbar.update()\n",
    "\n",
    "print(\"\\nAll activity accuracy: %.2f\" % (accuracy[\"all\"] / n_test))\n",
    "print(\"Proportion weighting accuracy: %.2f \\n\" % (accuracy[\"proportion\"] / n_test))\n",
    "\n",
    "\n",
    "print(\"Progress: %d / %d (%.4f seconds)\" % (epoch + 1, n_epochs, t() - start))\n",
    "print(\"Testing complete.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
